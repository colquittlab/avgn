{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:40:39.902496Z",
     "start_time": "2019-11-14T19:40:39.889279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:40:41.727350Z",
     "start_time": "2019-11-14T19:40:39.904189Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/tsainbur/github_repos/avgn_paper/avgn/utils/general.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from avgn.utils.paths import DATA_DIR, most_recent_subdirectory, ensure_dir\n",
    "from sklearn.preprocessing import scale\n",
    "from pyclustertend import hopkins, vat, ivat\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:40:41.757162Z",
     "start_time": "2019-11-14T19:40:41.729659Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.clusterability.hopkins import hopkins_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:40:41.858402Z",
     "start_time": "2019-11-14T19:40:41.759198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = list(DATA_DIR.glob('embeddings/*/*.pickle'))\n",
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:40:41.937653Z",
     "start_time": "2019-11-14T19:40:41.860076Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_outliers(z, pct = 99.5):\n",
    "    \"\"\" GPU based UMAP algorithm produces some outliers that UMAP does not, but is much faster\n",
    "    this is a quick fix for that. \n",
    "    \"\"\"\n",
    "    _min = np.percentile(z, (100-pct), axis=0)\n",
    "    _max = np.percentile(z, pct, axis=0)\n",
    "    for col in range(np.shape(z)[1]):\n",
    "        mask = z[:,col] < _min[col]\n",
    "        z[mask,col] = _min[col]\n",
    "        mask = z[:,col] > _max[col]\n",
    "        z[mask,col] = _max[col]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:40:42.019717Z",
     "start_time": "2019-11-14T19:40:41.940043Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_clusterability_df(dataset):\n",
    "\n",
    "    save_loc = DATA_DIR / 'clusterability' / 'convex_sample' / \\\n",
    "        (dataset.parent.stem + '_ ' + dataset.stem + '.pickle')\n",
    "\n",
    "    if save_loc.exists():\n",
    "        return\n",
    "\n",
    "    ds = pd.read_pickle(dataset)\n",
    "    specs = np.stack(ds[['spectrogram']].spectrogram.values)\n",
    "    specs = specs.reshape(len(specs), -1)\n",
    "    specs = scale(specs)\n",
    "\n",
    "    umap_proj = np.vstack(ds[['umap']].umap.values)\n",
    "    umap_proj = remove_outliers(umap_proj, pct=99.5)\n",
    "    umap_proj = scale(umap_proj)\n",
    "\n",
    "    print((dataset, np.shape(umap_proj)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(umap_proj[:, 0], umap_proj[:, 1], s=1, color='k', alpha=0.1)\n",
    "    plt.show()\n",
    "\n",
    "    hopkins_dict = {\n",
    "        'umap':\n",
    "        {\n",
    "            0.01: hopkins_statistic(umap_proj, m_prop_n=0.01, n_neighbors=1, distribution=\"uniform_convex_hull\"),\n",
    "            0.1: hopkins_statistic(umap_proj, m_prop_n=0.1, n_neighbors=1, distribution=\"uniform_convex_hull\"),\n",
    "        },\n",
    "\n",
    "    }\n",
    "\n",
    "    clusterability_df = pd.DataFrame([[dataset, dataset.parent.stem, dataset.stem,\n",
    "                                       hopkins_dict['umap'][0.01], hopkins_dict['umap'][0.1], ]], columns=[\n",
    "        'df', 'dataset', 'indv',\n",
    "        'umap_hopkins_1', 'umap_hopkins_10'\n",
    "    ])\n",
    "\n",
    "    clusterability_df.to_pickle(save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:40:42.112223Z",
     "start_time": "2019-11-14T19:40:42.021634Z"
    }
   },
   "outputs": [],
   "source": [
    "ensure_dir(DATA_DIR / 'clusterability' / 'convex_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:40:42.201884Z",
     "start_time": "2019-11-14T19:40:42.114052Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-14T19:40:46.387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e9dcacabc949668c32522e6ac5944c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=98), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "clust_data = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(gen_clusterability_df)(dataset)\n",
    "    for dataset in tqdm(datasets)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-py19] *",
   "language": "python",
   "name": "conda-env-anaconda3-py19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
