{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:31:08.280701Z",
     "start_time": "2020-04-24T19:31:08.270348Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:31:10.283542Z",
     "start_time": "2020-04-24T19:31:08.282546Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from avgn.utils.paths import DATA_DIR, most_recent_subdirectory, ensure_dir\n",
    "from sklearn.preprocessing import scale\n",
    "#from pyclustertend import hopkins, vat, ivat\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:31:10.302022Z",
     "start_time": "2020-04-24T19:31:10.285429Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.clusterability.hopkins import hopkins_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:31:10.339684Z",
     "start_time": "2020-04-24T19:31:10.304305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = list(DATA_DIR.glob('embeddings/**/*.pickle'))\n",
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:31:10.359334Z",
     "start_time": "2020-04-24T19:31:10.341902Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = [i for i in datasets if i.parent.stem not in [\n",
    "    'buckeye',\n",
    "    'BIRD_DB_Vireo_cassinii',\n",
    "    'swamp_sparrow',\n",
    "    'batsong_segmented'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:31:10.377324Z",
     "start_time": "2020-04-24T19:31:10.360671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:31:10.395225Z",
     "start_time": "2020-04-24T19:31:10.378615Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_outliers(z, pct = 99.5):\n",
    "    \"\"\" GPU based UMAP algorithm produces some outliers that UMAP does not, but is much faster\n",
    "    this is a quick fix for that. \n",
    "    \"\"\"\n",
    "    _min = np.percentile(z, (100-pct), axis=0)\n",
    "    _max = np.percentile(z, pct, axis=0)\n",
    "    for col in range(np.shape(z)[1]):\n",
    "        mask = z[:,col] < _min[col]\n",
    "        z[mask,col] = _min[col]\n",
    "        mask = z[:,col] > _max[col]\n",
    "        z[mask,col] = _max[col]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:31:10.411120Z",
     "start_time": "2020-04-24T19:31:10.396553Z"
    }
   },
   "outputs": [],
   "source": [
    "ensure_dir(DATA_DIR / 'clusterability' / 'convex_sample_indvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:31:10.431740Z",
     "start_time": "2020-04-24T19:31:10.412445Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_clusterability_df(dataset):\n",
    "    \"\"\"\n",
    "    m_prop_n is the number of samples over X to perform hopkins statistic on (.1 is reccomended)\n",
    "    \"\"\"\n",
    "    save_loc = DATA_DIR / 'clusterability' / 'convex_sample_indvs' / \\\n",
    "        (dataset.parent.stem + '_ ' + dataset.stem + '.pickle')\n",
    "\n",
    "    #if save_loc.exists():\n",
    "    #    return\n",
    "\n",
    "    ds = pd.read_pickle(dataset)\n",
    "    specs = np.stack(ds[['spectrogram']].spectrogram.values)\n",
    "    specs = specs.reshape(len(specs), -1)\n",
    "    specs = scale(specs)\n",
    "\n",
    "    umap_proj = np.vstack(ds[['umap']].umap.values)\n",
    "    umap_proj = remove_outliers(umap_proj, pct=99.5)\n",
    "    umap_proj = scale(umap_proj)\n",
    "    \n",
    "    nex = len(umap_proj)\n",
    "\n",
    "    print((dataset, np.shape(umap_proj)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(umap_proj[:, 0], umap_proj[:, 1], s=1, color='k', alpha=0.1)\n",
    "    plt.show()\n",
    "\n",
    "    hopkins_dict = {\n",
    "        'umap':\n",
    "        {\n",
    "            0.01: hopkins_statistic(umap_proj, m_prop_n=0.01, n_neighbors=1, distribution=\"uniform_convex_hull\"),\n",
    "            0.1: hopkins_statistic(umap_proj, m_prop_n=0.1, n_neighbors=1, distribution=\"uniform_convex_hull\"),\n",
    "        },\n",
    "\n",
    "    }\n",
    "    \n",
    "    dsname =  dataset.parent.parent.stem if dataset.parent.stem == 'indvs' else dataset.parent.stem\n",
    "\n",
    "    clusterability_df = pd.DataFrame([[dataset, dsname, dataset.stem,\n",
    "                                       hopkins_dict['umap'][0.01], hopkins_dict['umap'][0.1], nex]], columns=[\n",
    "        'df', 'dataset', 'indv',\n",
    "        'umap_hopkins_1', 'umap_hopkins_10', 'nex'\n",
    "    ])\n",
    "\n",
    "    clusterability_df.to_pickle(save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:31:10.447991Z",
     "start_time": "2020-04-24T19:31:10.433059Z"
    }
   },
   "outputs": [],
   "source": [
    "ensure_dir(DATA_DIR / 'clusterability' / 'convex_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:31:10.463901Z",
     "start_time": "2020-04-24T19:31:10.449342Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T19:31:39.483962Z",
     "start_time": "2020-04-24T19:31:10.465020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9808f9f2d9242c1993626179c700e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=291), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed:   12.7s\n",
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:   15.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 258 out of 291 | elapsed:   19.4s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 288 out of 291 | elapsed:   26.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 291 out of 291 | elapsed:   29.0s finished\n"
     ]
    }
   ],
   "source": [
    "clust_data = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(gen_clusterability_df)(dataset)\n",
    "    for dataset in tqdm(datasets)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
