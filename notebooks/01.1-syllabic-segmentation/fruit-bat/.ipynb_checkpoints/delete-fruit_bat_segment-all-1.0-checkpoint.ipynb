{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this segmentation is a sub-segmentation of the original segmentations provided by the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) create a dataset of syllable waveforms for each isolation segment\n",
    "\n",
    "2) get segmented times for each syllable in that segment\n",
    "\n",
    "3) create a new dataframe with the isolated syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:26:31.918097Z",
     "start_time": "2019-11-11T23:26:31.867390Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:26:37.486087Z",
     "start_time": "2019-11-11T23:26:31.920003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.autonotebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import umap\n",
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:26:37.756886Z",
     "start_time": "2019-11-11T23:26:37.493360Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.utils.paths import DATA_DIR, most_recent_subdirectory, ensure_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:26:37.806572Z",
     "start_time": "2019-11-11T23:26:37.762426Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_ID = 'batsong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:26:37.895137Z",
     "start_time": "2019-11-11T23:26:37.809256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-11-11_15-26-37'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a unique datetime identifier for the files output by this notebook\n",
    "DT_ID = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "DT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:26:37.982655Z",
     "start_time": "2019-11-11T23:26:37.897822Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.utils.hparams import HParams\n",
    "from avgn.dataset import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:26:38.073917Z",
     "start_time": "2019-11-11T23:26:37.986052Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.signalprocessing.create_spectrogram_dataset import prepare_wav, create_label_df, get_row_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:26:38.153011Z",
     "start_time": "2019-11-11T23:26:38.077984Z"
    }
   },
   "outputs": [],
   "source": [
    "hparams = HParams(\n",
    "    num_mel_bins = 32,\n",
    "    mel_lower_edge_hertz=500,\n",
    "    mel_upper_edge_hertz=120000,\n",
    "    butter_lowcut = 500,\n",
    "    butter_highcut = 120000,\n",
    "    ref_level_db = 20,\n",
    "    min_level_db = -60,\n",
    "    mask_spec = True,\n",
    "    win_length_ms = 0.5,\n",
    "    hop_length_ms = 0.05,\n",
    "    mask_spec_kwargs = {\"spec_thresh\": 0.9, \"offset\": 1e-10},\n",
    "    n_jobs = -1,\n",
    "    verbosity=1,\n",
    "    nex = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:27:01.538026Z",
     "start_time": "2019-11-11T23:26:38.155129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f897f38fad284fa39a8088651ff3958c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='loading json', max=83884, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1319 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 17819 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 40919 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 70619 tasks      | elapsed:   13.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 83884 out of 83884 | elapsed:   15.2s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='getting unique individuals', max=83884, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# create a dataset object\n",
    "dataset = DataSet(DATASET_ID, hparams = hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:27:01.601055Z",
     "start_time": "2019-11-11T23:27:01.540396Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset.data_files = {i:dataset.data_files[i] for i in list(dataset.data_files.keys())[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:27:01.724886Z",
     "start_time": "2019-11-11T23:27:01.602871Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fid', 166697),\n",
       "             ('Treatment ID', 17),\n",
       "             ('Recording channel', 1),\n",
       "             ('Recording time', '2013-01-16 08:06:24'),\n",
       "             ('indvs',\n",
       "              OrderedDict([('-210',\n",
       "                            OrderedDict([('syllables',\n",
       "                                          OrderedDict([('start_times',\n",
       "                                                        [4e-06]),\n",
       "                                                       ('end_times',\n",
       "                                                        [1.543488]),\n",
       "                                                       ('addressee', [-207]),\n",
       "                                                       ('context',\n",
       "                                                        ['Threat-like']),\n",
       "                                                       ('emit_prevoc_act',\n",
       "                                                        [2]),\n",
       "                                                       ('add_prevoc_act', [2]),\n",
       "                                                       ('emit_postvoc_act',\n",
       "                                                        [3]),\n",
       "                                                       ('add_postvoc_act',\n",
       "                                                        [3])]))]))])),\n",
       "             ('species', 'Rousettus aegyptiacus'),\n",
       "             ('common_name', 'Egyptian fruit bat'),\n",
       "             ('samplerate_hz', 250000),\n",
       "             ('original_wav',\n",
       "              '/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/raw/batsong/zip_contents/files212/130116080549387242.WAV'),\n",
       "             ('length_s', 1.543488),\n",
       "             ('wav_loc',\n",
       "              '/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/raw/batsong/zip_contents/files212/130116080549387242.WAV')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sample_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:27:01.809497Z",
     "start_time": "2019-11-11T23:27:01.726448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83884"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset based upon JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:27:01.891895Z",
     "start_time": "2019-11-11T23:27:01.811163Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "n_jobs = -1; verbosity = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:30:21.187627Z",
     "start_time": "2019-11-11T23:27:01.893651Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea4a3236b4e41ec9436e15aa7caa973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83884), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1841s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1301s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 271 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 535 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 673 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 823 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 973 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1135 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1297 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1471 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1645 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1831 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2017 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2215 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2413 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2623 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2833 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3055 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3277 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3511 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 3745 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3991 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4237 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 4495 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4753 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 5023 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 5293 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 5575 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 5857 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6151 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 6445 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 6751 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 7057 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 7375 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 7693 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 8023 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 8353 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 8695 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 9037 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 9391 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 9745 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 10111 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 10477 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 10855 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 11233 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 11623 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 12013 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 12415 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 12817 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 13231 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 13645 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 14071 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 14497 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 14935 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 15373 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 15823 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done 16273 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 16735 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done 17197 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done 17671 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Done 18145 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 18631 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 19117 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 19615 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 20113 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 20623 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 21133 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 21655 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 22177 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 22711 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 23245 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done 23791 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 24337 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done 24895 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done 25453 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=-1)]: Done 26023 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=-1)]: Done 26593 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 27175 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done 27757 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done 28351 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done 28945 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=-1)]: Done 29551 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done 30157 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=-1)]: Done 30775 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=-1)]: Done 31393 tasks      | elapsed:   49.3s\n",
      "[Parallel(n_jobs=-1)]: Done 32023 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=-1)]: Done 32653 tasks      | elapsed:   51.2s\n",
      "[Parallel(n_jobs=-1)]: Done 33295 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=-1)]: Done 33937 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=-1)]: Done 34591 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=-1)]: Done 35245 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=-1)]: Done 35911 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=-1)]: Done 36577 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 37255 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done 37933 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 38623 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 39313 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 40015 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 40717 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 41431 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 42145 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 42871 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 43597 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 44335 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 45073 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 45823 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 46573 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 47335 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 48097 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 48871 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 49645 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 50431 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 51217 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 52015 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 52813 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 53623 tasks      | elapsed:  1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 54433 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 55255 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 56077 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 56911 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 57745 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 58591 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 59437 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 60295 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 61153 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 62023 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 62893 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 63775 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 64657 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 65551 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 66445 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 67351 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 68257 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 69175 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 70093 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 71023 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 71953 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 72895 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 73837 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 74791 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 75745 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 76711 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 77677 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 78655 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 79633 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 80623 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 81613 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 82615 tasks      | elapsed:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 83884 out of 83884 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86867"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Parallel(n_jobs=n_jobs, verbose=verbosity) as parallel:\n",
    "    syllable_dfs = parallel(\n",
    "        delayed(create_label_df)(\n",
    "            dataset.data_files[key].data,\n",
    "            hparams=dataset.hparams,\n",
    "            labels_to_retain=[\"context\"],\n",
    "            unit=\"syllables\",\n",
    "            dict_features_to_retain = [],\n",
    "            key = key,\n",
    "        )\n",
    "        for key in tqdm(dataset.data_files.keys())\n",
    "    )\n",
    "syllable_df = pd.concat(syllable_dfs)\n",
    "len(syllable_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:30:21.885843Z",
     "start_time": "2019-11-11T23:30:21.189674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>context</th>\n",
       "      <th>indv</th>\n",
       "      <th>indvi</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.543488</td>\n",
       "      <td>Threat-like</td>\n",
       "      <td>-210</td>\n",
       "      <td>0</td>\n",
       "      <td>130116080549387242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.247424</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>-221</td>\n",
       "      <td>0</td>\n",
       "      <td>130303053329639859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.002284</td>\n",
       "      <td>2.166080</td>\n",
       "      <td>Isolation</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>121204031642219643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_time  end_time      context  indv  indvi                 key\n",
       "0    0.000004  1.543488  Threat-like  -210      0  130116080549387242\n",
       "0    0.000004  3.247424     Sleeping  -221      0  130303053329639859\n",
       "0    1.002284  2.166080    Isolation   222      0  121204031642219643"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllable_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:30:22.004401Z",
     "start_time": "2019-11-11T23:30:21.889073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Threat-like', 'Sleeping', 'Isolation', 'Fighting', 'General',\n",
       "       'Mating protest', 'Biting', 'Feeding', 'Kissing', 'Separation',\n",
       "       'Unknown', 'Grooming', 'Landing'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllable_df.context.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:30:22.218246Z",
     "start_time": "2019-11-11T23:30:22.006634Z"
    }
   },
   "outputs": [],
   "source": [
    "from vocalseg.dynamic_thresholding import dynamic_threshold_segmentation\n",
    "from vocalseg.dynamic_thresholding import plot_segmented_spec, plot_segmentations\n",
    "from vocalseg.utils import butter_bandpass_filter, spectrogram, int16tofloat32, plot_spec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save audio df for each context since this is a big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:30:22.289406Z",
     "start_time": "2019-11-11T23:30:22.220480Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fft=1024\n",
    "hop_length_ms=.5\n",
    "win_length_ms=4\n",
    "ref_level_db=20\n",
    "pre=0.97\n",
    "min_level_db=-30\n",
    "silence_threshold = 0.1\n",
    "min_silence_for_spec=0.1\n",
    "max_vocal_for_spec=1.0,\n",
    "min_syllable_length_s = 0.01\n",
    "spectral_range = [5000, 60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:30:22.404704Z",
     "start_time": "2019-11-11T23:30:22.291269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>context</th>\n",
       "      <th>indv</th>\n",
       "      <th>indvi</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.543488</td>\n",
       "      <td>Threat-like</td>\n",
       "      <td>-210</td>\n",
       "      <td>0</td>\n",
       "      <td>130116080549387242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.247424</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>-221</td>\n",
       "      <td>0</td>\n",
       "      <td>130303053329639859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_time  end_time      context  indv  indvi                 key\n",
       "0    0.000004  1.543488  Threat-like  -210      0  130116080549387242\n",
       "0    0.000004  3.247424     Sleeping  -221      0  130303053329639859"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllable_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:50:47.141531Z",
     "start_time": "2019-11-11T23:50:47.057221Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.utils.audio import int16_to_float32\n",
    "from avgn.signalprocessing.filtering import butter_bandpass_filter\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:51:43.679217Z",
     "start_time": "2019-11-11T23:51:43.107476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>context</th>\n",
       "      <th>indv</th>\n",
       "      <th>indvi</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.543488</td>\n",
       "      <td>Threat-like</td>\n",
       "      <td>-210</td>\n",
       "      <td>0</td>\n",
       "      <td>130116080549387242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.247424</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>-221</td>\n",
       "      <td>0</td>\n",
       "      <td>130303053329639859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.002284</td>\n",
       "      <td>2.166080</td>\n",
       "      <td>Isolation</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>121204031642219643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_time  end_time      context  indv  indvi                 key\n",
       "0    0.000004  1.543488  Threat-like  -210      0  130116080549387242\n",
       "0    0.000004  3.247424     Sleeping  -221      0  130303053329639859\n",
       "0    1.002284  2.166080    Isolation   222      0  121204031642219643"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllable_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T00:11:34.197126Z",
     "start_time": "2019-11-12T00:11:30.115354Z"
    }
   },
   "outputs": [],
   "source": [
    "butter_lowcut = 500\n",
    "butter_highcut = 120000\n",
    "def create_segmented_json(row):\n",
    "    # load audio\n",
    "    # get rate and date\n",
    "    wav_loc = dataset.data_files[row.key].data['wav_loc']\n",
    "    duration = row.end_time - row.start_time\n",
    "    \"\"\"data, rate = librosa.core.load(wav_loc, sr=None, offset = row.start_time, duration = duration)\n",
    "\n",
    "    # convert data if needed\n",
    "    if np.issubdtype(type(data[0]), np.integer):\n",
    "        data = int16_to_float32(data)\n",
    "    # bandpass filter\n",
    "    data = butter_bandpass_filter(\n",
    "        data, butter_lowcut, butter_highcut, rate, order=5\n",
    "    )\n",
    "\n",
    "    results = dynamic_threshold_segmentation(\n",
    "        data,\n",
    "        rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length_ms=hop_length_ms,\n",
    "        win_length_ms=win_length_ms,\n",
    "        ref_level_db=ref_level_db,\n",
    "        pre=pre,\n",
    "        min_level_db=min_level_db,\n",
    "        silence_threshold=silence_threshold,\n",
    "        verbose=False,\n",
    "        spectral_range=spectral_range,\n",
    "        min_syllable_length_s=min_syllable_length_s,\n",
    "        min_level_db_floor=20,\n",
    "\n",
    "    )\n",
    "    if results is None:\n",
    "        return None, None\n",
    "    return results['onsets'], results['offsets']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-12T00:11:35.705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803d9eb7c3624a9b8c820019aa135b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=86867), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1850s.) Setting batch_size=2.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n'''\nTraceback (most recent call last):\n  File \"/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 391, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/multiprocessing/queues.py\", line 99, in get\n    if not self._rlock.acquire(block, timeout):\nKeyboardInterrupt\n'''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-9321a27bcfe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         )\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyllable_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyllable_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monsets_offsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    853\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0mdelete_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 \u001b[0mqmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0mcq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "with Parallel(n_jobs=-1, verbose=verbosity) as parallel:\n",
    "    onsets_offsets = parallel(\n",
    "        delayed(create_segmented_json)(\n",
    "            row\n",
    "        )\n",
    "        for idx, row in tqdm(syllable_df.iterrows(), total=len(syllable_df))\n",
    "    )\n",
    "len(onsets_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:36:33.957634Z",
     "start_time": "2019-11-11T23:26:31.490Z"
    }
   },
   "outputs": [],
   "source": [
    "breakme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:36:33.959390Z",
     "start_time": "2019-11-11T23:26:31.492Z"
    }
   },
   "outputs": [],
   "source": [
    "syllable_df['start_times'] = start_times\n",
    "syllable_df['end_times'] = end_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:36:33.961138Z",
     "start_time": "2019-11-11T23:26:31.546Z"
    }
   },
   "outputs": [],
   "source": [
    "display_results=False\n",
    "start_times = []\n",
    "end_times = []\n",
    "for idx, row in tqdm(syllable_df.iterrows(), total=len(syllable_df)):\n",
    "    \n",
    "    # load audio\n",
    "    rate, data = prepare_wav(dataset.data_files[row.key].data['wav_loc'], hparams)\n",
    "    \n",
    "    results = dynamic_threshold_segmentation(\n",
    "        data,\n",
    "        rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length_ms=hop_length_ms,\n",
    "        win_length_ms=win_length_ms,\n",
    "        ref_level_db=ref_level_db,\n",
    "        pre=pre,\n",
    "        min_level_db=min_level_db,\n",
    "        \n",
    "        silence_threshold=silence_threshold,\n",
    "        verbose=False,\n",
    "        spectral_range=spectral_range,\n",
    "        min_syllable_length_s=min_syllable_length_s,\n",
    "                min_level_db_floor=20,\n",
    "\n",
    "    )\n",
    "    \n",
    "    if results is None:\n",
    "        if display_results:\n",
    "            spec = spectrogram(\n",
    "                row.audio,\n",
    "                row.rate,\n",
    "                n_fft=n_fft,\n",
    "                hop_length_ms=hop_length_ms,\n",
    "                win_length_ms=win_length_ms,\n",
    "                ref_level_db=ref_level_db,\n",
    "                pre=pre,\n",
    "                min_level_db=min_level_db,\n",
    "            )\n",
    "            fig, ax = plt.subplots(figsize=(30,5))\n",
    "            plot_spec(spec, fig, ax);\n",
    "            plt.show()\n",
    "        start_times.append(None)\n",
    "        end_times.append(None)\n",
    "        continue\n",
    "    else:\n",
    "        if display_results:\n",
    "            plot_segmentations(\n",
    "                results[\"spec\"],\n",
    "                vocal_envelope=results[\"vocal_envelope\"],\n",
    "                onsets=results[\"onsets\"],\n",
    "                offsets=results[\"offsets\"],\n",
    "                rate=row.rate,\n",
    "                hop_length_ms=hop_length_ms,\n",
    "                figsize=(30, 5),\n",
    "                #spectral_range=spectral_range\n",
    "            )\n",
    "            plt.show()\n",
    "            \n",
    "    start_times.append(results['onsets'])\n",
    "    end_times.append(results['offsets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T23:36:33.962860Z",
     "start_time": "2019-11-11T23:26:31.555Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for context in tqdm(syllable_df.context.unique()):\n",
    "    \n",
    "    save_loc = (DATA_DIR\n",
    "        / \"audio_df\"\n",
    "        / (DATASET_ID + context + '.pickle'))\n",
    "    \n",
    "    if save_loc.exists():\n",
    "        continue \n",
    "        \n",
    "    # get only isolation calls\n",
    "    subset_df = syllable_df[syllable_df.context == context]\n",
    "    print(context, len(subset_df))\n",
    "    \n",
    "    with Parallel(n_jobs=n_jobs, verbose=0) as parallel:\n",
    "        syllable_dfs = parallel(\n",
    "            delayed(get_row_audio)(\n",
    "                subset_df[subset_df.key == key], \n",
    "                dataset.data_files[key].data['wav_loc'], \n",
    "                dataset.hparams\n",
    "            )\n",
    "            for key in tqdm(subset_df.key.unique(), leave=False)\n",
    "        )\n",
    "    subset_df = pd.concat(syllable_dfs)\n",
    "    print(len(subset_df))\n",
    "    \n",
    "    # mask short audio\n",
    "    df_mask  = np.array([len(i) > 0 for i in tqdm(subset_df.audio.values)])\n",
    "    subset_df = subset_df[np.array(df_mask)]\n",
    "    \n",
    "    # normalize audio\n",
    "    subset_df['audio'] = [i/np.max(np.abs(i)) for i in tqdm(subset_df.audio.values)]\n",
    "    \n",
    "    # plot\n",
    "    nrows = 5; ncols = 10\n",
    "    zoom = 2\n",
    "    fig, axs = plt.subplots(ncols=ncols, nrows = nrows,figsize = (ncols*zoom, nrows+zoom/1.5))\n",
    "    for i, syll in tqdm(enumerate(subset_df.audio.values), total = nrows*ncols):\n",
    "        ax = axs.flatten()[i]\n",
    "        ax.plot(syll)\n",
    "        if i == nrows*ncols -1:\n",
    "            break\n",
    "    plt.show()\n",
    "    \n",
    "    # save\n",
    "    save_loc = (DATA_DIR\n",
    "        / \"audio_df\"\n",
    "        / (DATASET_ID + context + '.pickle'))\n",
    "    ensure_dir(save_loc)\n",
    "    subset_df.to_pickle(save_loc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
