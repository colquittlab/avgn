{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T20:45:49.989430Z",
     "start_time": "2020-04-06T20:45:49.973425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T20:45:52.701594Z",
     "start_time": "2020-04-06T20:45:49.990790Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pandas as pd\n",
    "from cuml.manifold.umap import UMAP as cumlUMAP\n",
    "from avgn.utils.paths import DATA_DIR, most_recent_subdirectory, ensure_dir\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T20:45:53.341637Z",
     "start_time": "2020-04-06T20:45:52.703443Z"
    }
   },
   "outputs": [],
   "source": [
    "import pomegranate\n",
    "from pomegranate import DiscreteDistribution, HiddenMarkovModel\n",
    "pomegranate.utils.disable_gpu()\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit models code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T20:45:53.387696Z",
     "start_time": "2020-04-06T20:45:53.345198Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def AIC(log_likelihood, k):\n",
    "    \"\"\" AIC given log_likelihood and # parameters (k)\n",
    "    \"\"\"\n",
    "    aic = 2 * k - 2 * log_likelihood\n",
    "    return aic\n",
    "\n",
    "\n",
    "def BIC(log_likelihood, n, k):\n",
    "    \"\"\" BIC given log_likelihood, number of observations (n) and # parameters (k)\n",
    "    \"\"\"\n",
    "    bic = np.log(n) * k - 2 * log_likelihood\n",
    "    return bic\n",
    "\n",
    "def FOMM(seqs, prop_test=0.5):\n",
    "    \"\"\" create a FOMM in pomegranite\n",
    "    \"\"\"\n",
    "    if prop_test == 0:\n",
    "        seqs_train = seqs_test = seqs\n",
    "    else:\n",
    "        # split into train and test for cross validation\n",
    "        training_mask = np.random.choice(\n",
    "            np.arange(len(seqs)), size=int(len(seqs) * prop_test), replace=False\n",
    "        )\n",
    "        testing_mask = np.array(\n",
    "            [i for i in np.arange(len(seqs)) if i not in training_mask]\n",
    "        )\n",
    "\n",
    "        seqs_train = np.array(seqs)[training_mask]\n",
    "        seqs_test = np.array(seqs)[testing_mask]\n",
    "\n",
    "        # make sure test set doesn't contain any data that train doesnt\n",
    "        assert np.all(\n",
    "            [\n",
    "                i in np.unique(np.concatenate(seqs_train))\n",
    "                for i in np.unique(np.concatenate(seqs_test))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # lengths of sequences\n",
    "    seq_lens = [len(i) for i in seqs_train]\n",
    "\n",
    "    # get states\n",
    "    unique_states = np.unique(np.concatenate(seqs_train))\n",
    "\n",
    "    # get start probabilities\n",
    "    seq_starts = np.array([i[0] for i in seqs_train])\n",
    "    start_probs = [np.sum(seq_starts == i) / len(seqs_train) for i in unique_states]\n",
    "\n",
    "    end_states = [seq[-1] for seq in seqs]\n",
    "    end_probs = [\n",
    "        np.sum(end_states == i) / (np.sum(np.concatenate(seqs) == i) + 1)\n",
    "        for i in np.arange(len(unique_states))\n",
    "    ]\n",
    "\n",
    "    # transition probs\n",
    "    trans_mat = np.zeros((len(unique_states), len(unique_states)))\n",
    "    for seq in seqs_train:\n",
    "        for i, j in zip(seq[:-1], seq[1:]):\n",
    "            trans_mat[i, j] += 1\n",
    "    # smooth to nonzero probabilities\n",
    "    trans_mat = (trans_mat.T / trans_mat.sum(axis=1)).T  # np.sum(trans_mat, axis=1)\n",
    "\n",
    "    # smooth emissions\n",
    "    emission_prob = np.identity(len(unique_states)) + 1e-5\n",
    "    emission_prob = (emission_prob.T / emission_prob.sum(axis=1)).T\n",
    "\n",
    "    # number of datapoints\n",
    "    test_seq_lens = [len(i) for i in seqs_test]\n",
    "    n_data = np.sum(test_seq_lens)\n",
    "\n",
    "    # initialize pomegranate model\n",
    "\n",
    "    transmat = trans_mat\n",
    "    start_probs = start_probs\n",
    "    dists = emission_prob\n",
    "\n",
    "    states = [\n",
    "        DiscreteDistribution({vis: d[i] for i, vis in enumerate(unique_states)})\n",
    "        for d in dists\n",
    "    ]\n",
    "    pom_model = HiddenMarkovModel.from_matrix(\n",
    "        transition_probabilities=transmat,\n",
    "        distributions=states,\n",
    "        starts=start_probs,\n",
    "        ends=end_probs,  # discluding ends and merge makes models equal log prob\n",
    "        merge=\"None\",\n",
    "    )\n",
    "    pom_model.bake()\n",
    "    pom_log_probability = np.sum([pom_model.log_probability(seq) for seq in seqs_test])\n",
    "    \n",
    "\n",
    "    # number of params in model\n",
    "    num_params = (\n",
    "        pom_model.edge_count() + pom_model.node_count() + pom_model.state_count()  # no hidden states in FOMM\n",
    "    )\n",
    "\n",
    "    # AIC and BIC\n",
    "    aic = AIC(pom_log_probability, num_params)\n",
    "    bic = BIC(pom_log_probability, n_data, num_params)\n",
    "    return (\n",
    "        pom_model,\n",
    "        seqs_train,\n",
    "        seqs_test,\n",
    "        pom_log_probability,\n",
    "        num_params,\n",
    "        n_data,\n",
    "        aic,\n",
    "        bic,\n",
    "    )\n",
    "\n",
    "def fit_fixed_latent(seqs, latent_seqs, verbose=False):\n",
    "\n",
    "    unique_latent_labels = np.unique(np.concatenate(latent_seqs))\n",
    "    n_components = len(unique_latent_labels)\n",
    "\n",
    "    # convert latent sequences to correct format\n",
    "    label_seqs_str = [\n",
    "        [\"None-start\"] + [\"s\" + str(i) for i in seq] + [\"None-end\"]\n",
    "        for seq in latent_seqs\n",
    "    ]\n",
    "    \n",
    "    pom_model = HiddenMarkovModel.from_samples(\n",
    "        distribution=DiscreteDistribution,\n",
    "        n_components=len(unique_latent_labels),\n",
    "        X=seqs,\n",
    "        labels=label_seqs_str,\n",
    "        end_state=True,\n",
    "        algorithm=\"labeled\",\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    log_prob = [pom_model.log_probability(seq) for seq in seqs]\n",
    "\n",
    "    sum_log_prob = np.sum(log_prob)\n",
    "    \n",
    "    num_params = (\n",
    "        pom_model.state_count() + pom_model.edge_count() + pom_model.node_count()\n",
    "    )\n",
    "\n",
    "    n_data = np.sum([len(i) for i in seqs])\n",
    "\n",
    "    aic = AIC(sum_log_prob, num_params)\n",
    "    bic = BIC(sum_log_prob, n_data, num_params)\n",
    "\n",
    "    return pom_model, log_prob, sum_log_prob, n_components, num_params, n_data, aic, bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T20:45:53.415415Z",
     "start_time": "2020-04-06T20:45:53.390394Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_ID = 'koumura_bengalese_finch'\n",
    "embeddings_dfs = list(DATA_DIR.glob('bf_label_dfs/'+DATASET_ID+'/*.pickle'))\n",
    "DATASET_ID = 'bengalese_finch_sober'\n",
    "embeddings_dfs = embeddings_dfs + list(DATA_DIR.glob('bf_label_dfs/'+DATASET_ID+'/*.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T20:45:53.438422Z",
     "start_time": "2020-04-06T20:45:53.416467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/koumura_bengalese_finch/Bird9.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/koumura_bengalese_finch/Bird4.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/koumura_bengalese_finch/Bird10.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/koumura_bengalese_finch/Bird6.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/koumura_bengalese_finch/Bird0.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/koumura_bengalese_finch/Bird2.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/koumura_bengalese_finch/Bird1.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/koumura_bengalese_finch/Bird3.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/koumura_bengalese_finch/Bird5.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/koumura_bengalese_finch/Bird8.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/koumura_bengalese_finch/Bird7.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/bengalese_finch_sober/bl26lb16.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/bengalese_finch_sober/gy6or6.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/bengalese_finch_sober/or60yw70.pickle'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data/bf_label_dfs/bengalese_finch_sober/gr41rd51.pickle')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T20:48:09.523591Z",
     "start_time": "2020-04-06T20:45:53.439565Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17484915c4b345739491bf1cf17e8ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Bird9---\\AIC: \n",
      "\tSOMM: 19098.0\n",
      "\tFOMM: 22824.0 \n",
      "\tHDBSCAN: 23352.0 \n",
      "LL: \n",
      "\tSOMM: -9108.0\n",
      "\tFOMM: -11243.0 \n",
      "\tHDBSCAN: -11644.0\n",
      "---Bird4---\\AIC: \n",
      "\tSOMM: 31000.0\n",
      "\tFOMM: 31417.0 \n",
      "\tHDBSCAN: 32006.0 \n",
      "LL: \n",
      "\tSOMM: -15100.0\n",
      "\tFOMM: -15627.0 \n",
      "\tHDBSCAN: -15973.0\n",
      "---Bird10---\\AIC: \n",
      "\tSOMM: 10432.0\n",
      "\tFOMM: 7775.0 \n",
      "\tHDBSCAN: 8867.0 \n",
      "LL: \n",
      "\tSOMM: -3100.0\n",
      "\tFOMM: -3446.0 \n",
      "\tHDBSCAN: -4367.0\n",
      "---Bird6---\\AIC: \n",
      "\tSOMM: 23582.0\n",
      "\tFOMM: 24004.0 \n",
      "\tHDBSCAN: 25202.0 \n",
      "LL: \n",
      "\tSOMM: -11307.0\n",
      "\tFOMM: -11858.0 \n",
      "\tHDBSCAN: -12570.0\n",
      "---Bird0---\\AIC: \n",
      "\tSOMM: 10503.0\n",
      "\tFOMM: 10124.0 \n",
      "\tHDBSCAN: 13339.0 \n",
      "LL: \n",
      "\tSOMM: -4027.0\n",
      "\tFOMM: -4738.0 \n",
      "\tHDBSCAN: -6619.0\n",
      "---Bird2---\\AIC: \n",
      "\tSOMM: 20745.0\n",
      "\tFOMM: 18910.0 \n",
      "\tHDBSCAN: 18680.0 \n",
      "LL: \n",
      "\tSOMM: -8348.0\n",
      "\tFOMM: -8879.0 \n",
      "\tHDBSCAN: -9263.0\n",
      "---Bird1---\\AIC: \n",
      "\tSOMM: 45255.0\n",
      "\tFOMM: 43808.0 \n",
      "\tHDBSCAN: 53080.0 \n",
      "LL: \n",
      "\tSOMM: -18783.0\n",
      "\tFOMM: -21420.0 \n",
      "\tHDBSCAN: -26454.0\n",
      "---Bird3---\\AIC: \n",
      "\tSOMM: 43372.0\n",
      "\tFOMM: 43977.0 \n",
      "\tHDBSCAN: 45204.0 \n",
      "LL: \n",
      "\tSOMM: -19922.0\n",
      "\tFOMM: -21732.0 \n",
      "\tHDBSCAN: -22544.0\n",
      "---Bird5---\\AIC: \n",
      "\tSOMM: 17873.0\n",
      "\tFOMM: 20097.0 \n",
      "\tHDBSCAN: 34613.0 \n",
      "LL: \n",
      "\tSOMM: -8207.0\n",
      "\tFOMM: -9648.0 \n",
      "\tHDBSCAN: -17267.0\n",
      "---Bird8---\\AIC: \n",
      "\tSOMM: 6514.0\n",
      "\tFOMM: 6735.0 \n",
      "\tHDBSCAN: 6486.0 \n",
      "LL: \n",
      "\tSOMM: -3032.0\n",
      "\tFOMM: -3198.0 \n",
      "\tHDBSCAN: -3220.0\n",
      "---Bird7---\\AIC: \n",
      "\tSOMM: 25480.0\n",
      "\tFOMM: 31353.0 \n",
      "\tHDBSCAN: 34692.0 \n",
      "LL: \n",
      "\tSOMM: -12115.0\n",
      "\tFOMM: -15316.0 \n",
      "\tHDBSCAN: -17308.0\n",
      "---bl26lb16---\\AIC: \n",
      "\tSOMM: 77867.0\n",
      "\tFOMM: 83509.0 \n",
      "\tHDBSCAN: 77109.0 \n",
      "LL: \n",
      "\tSOMM: -33158.0\n",
      "\tFOMM: -41559.0 \n",
      "\tHDBSCAN: -38445.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/ipykernel_launcher.py:61: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---gy6or6---\\AIC: \n",
      "\tSOMM: 22492.0\n",
      "\tFOMM: 36469.0 \n",
      "\tHDBSCAN: 37280.0 \n",
      "LL: \n",
      "\tSOMM: -9130.0\n",
      "\tFOMM: -17911.0 \n",
      "\tHDBSCAN: -18546.0\n",
      "---or60yw70---\\AIC: \n",
      "\tSOMM: 36763.0\n",
      "\tFOMM: 33728.0 \n",
      "\tHDBSCAN: 44021.0 \n",
      "LL: \n",
      "\tSOMM: -16172.0\n",
      "\tFOMM: -16608.0 \n",
      "\tHDBSCAN: -21937.0\n",
      "---gr41rd51---\\AIC: \n",
      "\tSOMM: 68759.0\n",
      "\tFOMM: 57241.0 \n",
      "\tHDBSCAN: 45385.0 \n",
      "LL: \n",
      "\tSOMM: -19003.0\n",
      "\tFOMM: -28297.0 \n",
      "\tHDBSCAN: -22533.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for loc in tqdm(embeddings_dfs):\n",
    "    # read dataframe\n",
    "    indv_df = pd.read_pickle(loc).sort_values(by=[\"key\", \"start_time\"])\n",
    "    indv = indv_df.indv.unique()[0]\n",
    "\n",
    "    # Get seqs\n",
    "    hand_seqs = [\n",
    "        list(indv_df[indv_df.syllables_sequence_id == seqid][\"labels_num\"].values)\n",
    "        for seqid in indv_df.syllables_sequence_id.unique()\n",
    "    ]\n",
    "\n",
    "    results_df_FOMM = pd.DataFrame(\n",
    "        [FOMM(hand_seqs, prop_test=0)],\n",
    "        columns=[\n",
    "            \"pom_model\",\n",
    "            \"seqs_train\",\n",
    "            \"seqs_test\",\n",
    "            \"pom_log_probability\",\n",
    "            \"n_params\",\n",
    "            \"n_data\",\n",
    "            \"aic\",\n",
    "            \"bic\",\n",
    "        ],\n",
    "    )\n",
    "    results_df_FOMM[\"indv\"] = indv\n",
    "    save_loc = DATA_DIR / \"HMM_fits\" / \"FOMM\" / (indv + \".pickle\")\n",
    "    ensure_dir(save_loc)\n",
    "    results_df_FOMM.to_pickle(save_loc)\n",
    "\n",
    "    ### HDBSCAN as latent\n",
    "    # HDBSCAN seqs\n",
    "    \n",
    "    for hdbscan_labels in [\"hdbscan_labels_num\", \"hdbscan_labels-0.1_num\",  \"hdbscan_labels-0.25_num\"]:\n",
    "        hdbscan_latent_seqs = [\n",
    "            list(\n",
    "                indv_df[indv_df.syllables_sequence_id == seqid][hdbscan_labels].values\n",
    "            )\n",
    "            for seqid in indv_df.syllables_sequence_id.unique()\n",
    "        ]\n",
    "\n",
    "        # make latent df\n",
    "        results_df_umap_hidden = pd.DataFrame(\n",
    "            [fit_fixed_latent(hand_seqs, hdbscan_latent_seqs, verbose=False)],\n",
    "            columns=[\n",
    "                \"pom_model\",\n",
    "                \"log_prob\",\n",
    "                \"sum_log_prob\",\n",
    "                \"n_components\",\n",
    "                \"num_params\",\n",
    "                \"n_data\",\n",
    "                \"aic\",\n",
    "                \"bic\",\n",
    "            ],\n",
    "        )\n",
    "        results_df_umap_hidden[\"indv\"] = indv\n",
    "        save_loc = DATA_DIR / \"HMM_fits\"  / hdbscan_labels / \"HDBSCAN\" / (indv + \".pickle\")\n",
    "        ensure_dir(save_loc)\n",
    "        results_df_umap_hidden.to_pickle(save_loc)\n",
    "\n",
    "    ### second order model\n",
    "    seqs_second_order_states = [\n",
    "        list(\n",
    "            indv_df[indv_df.syllables_sequence_id == seqid][\n",
    "                \"seqs_second_order_states\"\n",
    "            ].values\n",
    "        )\n",
    "        for seqid in indv_df.syllables_sequence_id.unique()\n",
    "    ]\n",
    "\n",
    "    results_df_second_order_hidden = pd.DataFrame(\n",
    "        [fit_fixed_latent(hand_seqs, seqs_second_order_states, verbose=False)],\n",
    "        columns=[\n",
    "            \"pom_model\",\n",
    "            \"log_prob\",\n",
    "            \"sum_log_prob\",\n",
    "            \"n_components\",\n",
    "            \"num_params\",\n",
    "            \"n_data\",\n",
    "            \"aic\",\n",
    "            \"bic\",\n",
    "        ],\n",
    "    )\n",
    "    results_df_second_order_hidden[\"indv\"] = indv\n",
    "    save_loc = DATA_DIR / \"SOMM\" / (indv + \".pickle\")\n",
    "    ensure_dir(save_loc)\n",
    "    results_df_second_order_hidden.to_pickle(save_loc)\n",
    "\n",
    "    print(\n",
    "        \"---{}---\\nAIC: \\n\\tSOMM: {}\\n\\tFOMM: {} \\n\\tHDBSCAN: {} \\nLL: \\n\\tSOMM: {}\\n\\tFOMM: {} \\n\\tHDBSCAN: {}\".format(\n",
    "            indv,\n",
    "            round(results_df_second_order_hidden.aic.values[0]),\n",
    "            round(results_df_umap_hidden.aic.values[0]),\n",
    "            round(results_df_FOMM.aic.values[0]),\n",
    "            round(results_df_second_order_hidden.sum_log_prob.values[0]),\n",
    "            round(results_df_umap_hidden.sum_log_prob.values[0]),\n",
    "            round(results_df_FOMM.pom_log_probability.values[0]),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T20:48:09.588569Z",
     "start_time": "2020-04-06T20:48:09.525307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/cube/tsainbur/Projects/github_repos/avgn_paper/data')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
